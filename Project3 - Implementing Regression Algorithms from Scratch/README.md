# Project 3 - Implementing Regression algorithms from Scratch 

Goal: To understand how Regression Algorithms are built, and learn the underlying mechanics of the algorithms by building the Algorithms from Scratch.

For this project, I’ll implement the following regression algorithms and compare their performance with the Scikit Learn’s Implementations.

1. Linear Regression
2. Logistic Regression

**Linear Regression**

Simple Linear Regression is implemented by using both 
- [Gradient Descent Optimization](https://github.com/laxmena/100MLProjects/blob/master/Project3%20-%20Implementing%20Regression%20Algorithms%20from%20Scratch/3_1_1_Linear_Regression_Gradient_Descent.ipynb) and 
- [Ordinary least squares(OLS)](https://github.com/laxmena/100MLProjects/blob/master/Project3%20-%20Implementing%20Regression%20Algorithms%20from%20Scratch/3_1_2_Linear_Regression_OLS.ipynb)

Here is a visualization of the Gradient Descent Optimization:
![Gradient Descent](gradient_descent_animation.gif)

**Logistic Regression**

In Logistic regression, Binary classification and multi-class classification has been implemented.

- [Logistic Regression: Binary Classification](https://github.com/laxmena/100MLProjects/blob/master/Project3%20-%20Implementing%20Regression%20Algorithms%20from%20Scratch/3_2_1_Logistic_Regression.ipynb)
- [Logistic Regression: MultiClass Classification](https://github.com/laxmena/100MLProjects/blob/master/Project3%20-%20Implementing%20Regression%20Algorithms%20from%20Scratch/3_2_2_Logistic_Regression_OneVsAll.ipynb)

**Suggestions and Feedback:**
I highly value your suggestions and feedback, if you have any please share them to me through [LinkedIn](https://www.linkedin.com/in/lakshmanan-meiyappan/) or [Email](mailto:writeto@laxmena.com).

## About #100MLProjects
100MLProjects is a Challenge where I try to attain proficiency in Machine Learning and Deep Learning concepts by doing 100 Projects. The complexity of the projects keeps increasing as I progress through the challenge, so other Machine Learning/Deep Learning aspirants can also follow this path.